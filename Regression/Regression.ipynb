{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-_x-VIiy1Y6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EwE_aUS00xp",
        "outputId": "5d499fc5-b9dc-41e6-97e3-4c0a65567499"
      },
      "source": [
        "!pip uninstall scikit-learn -y"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling scikit-learn-0.22.2.post1:\n",
            "  Successfully uninstalled scikit-learn-0.22.2.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3qoHyDf1CfR",
        "outputId": "40bab6e0-f850-40e3-e1c0-397165bb73b4"
      },
      "source": [
        "!pip install -U scikit-learn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 67.3MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "Successfully installed scikit-learn-0.24.2 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVauxGTuCHG6",
        "outputId": "dcf575d9-dacd-49e8-c4f9-3ec7d2f2fc33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEgeVBdL1QLh"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 20, 10\n",
        "import gc\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import *\n",
        "from dateutil import parser\n",
        "from datetime import datetime\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from itertools import product\n",
        "import torch\n",
        "from torch import nn, from_numpy\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from scipy.sparse import coo_matrix, hstack"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVgzydlKy2TJ"
      },
      "source": [
        "def rmse(y_true, y_pred):\n",
        "\n",
        "    return mean_squared_error(\n",
        "            y_true=y_true,\n",
        "            y_pred=y_pred,\n",
        "            squared=False\n",
        "        )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNSD9-qozNqi"
      },
      "source": [
        "df_train = pd.read_csv(r'/content/drive/MyDrive/regression/train.csv')\n",
        "df_test = pd.read_csv(r'/content/drive/MyDrive/regression/test.csv')\n",
        "df_submission = pd.read_csv(r'/content/drive/MyDrive/regression/submission.csv')\n",
        "df_store = pd.read_csv(r'/content/drive/MyDrive/regression/store.csv')\n",
        "df_article = pd.read_csv(r'/content/drive/MyDrive/regression/article.csv')\n",
        "df_sales_count = pd.read_csv(r'/content/drive/MyDrive/regression/sales_count.csv')\n",
        "df_holidays = pd.read_csv(r'/content/drive/MyDrive/regression/holidays.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYqdKzLaficR"
      },
      "source": [
        "Таблицы article и store содержат категориальные признаки, информация о которых содержится в столбцах ARTICLE_ID и STORE_ID. Поэтому эти признаки излишние, что подтверждают эксперименты с линейной регрессией.\n",
        "\n",
        "Добавим в качестве признака день недели и построим простой бэйзлайн - линейную регрессию на все имеющиеся признаки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVtzv35jy9_6"
      },
      "source": [
        "df_train = pd.merge(df_train,df_sales_count)\n",
        "df_train['IS_HOLIDAY'] = df_train['DAY_ID'].apply(lambda x: x in df_holidays['DAY_ID'].values)\n",
        "df_train['WEEKDAY'] = df_train.DAY_ID.apply(lambda x: datetime.strptime(x,'%Y-%m-%d').weekday())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPrtatAxL2St"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d07otjjTjCdK"
      },
      "source": [
        "Разобьем данные для обучения и валидации. В качестве валидационного датасета возьмем 15 последних дней из обучающей выборки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYrYSdSen_Fc"
      },
      "source": [
        "X_train,y_train,X_val,y_val = df_train[df_train['DAY_ID']<='2017-07-16'].drop(['DAY_ID','SALES'],axis=1),df_train[df_train['DAY_ID']<='2017-07-16']['SALES'].values,\\\n",
        "df_train[df_train['DAY_ID']>'2017-07-16'].drop(['DAY_ID','SALES'],axis=1),df_train[df_train['DAY_ID']>'2017-07-16']['SALES'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X3mF3auGagV"
      },
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdRx5bwKJ2CL"
      },
      "source": [
        "X_train_trans = hstack([enc.fit_transform(X_train.drop(['SALES_COUNT'],axis=1)),coo_matrix(X_train[['SALES_COUNT']].values)])\n",
        "X_val_trans = hstack([enc.transform(X_val.drop(['SALES_COUNT'],axis=1)),coo_matrix(X_val[['SALES_COUNT']].values)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KdRXxhIC3lb"
      },
      "source": [
        "reg = LinearRegression().fit(X_train_trans,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK9kuTLtKKTk",
        "outputId": "54c47a00-d038-40f2-e16d-1c649396cd96"
      },
      "source": [
        "print(\"Результаты для линейной регрессии:\")\n",
        "print( 'RMSE on train: {}, RMSE on val: {}'.format( rmse(y_train,reg.predict(X_train_trans)), rmse(y_val,reg.predict(X_val_trans)) ) )\n",
        "print( 'R2 on train: {}, R2 on val: {}'.format( reg.score(X_train_trans,y_train), reg.score(X_val_trans,y_val) ) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Результаты для линейной регрессии:\n",
            "RMSE on train: 22.577699607412015, RMSE on val: 21.870995473243475\n",
            "R2 on train: 0.2078610578010318, R2 on val: 0.2032628995910768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQzhqdfPj-f6"
      },
      "source": [
        "В данной модели не учитывается временная структура данных. Поэтому мы можем, например, использовать реккурентную нейронную сеть LSTM для учета временной структуры данных. Как показали эксперименты, лучше прогнозировать продажи отдельно для каждого магазина, т е создать и обучить нейронную сеть для каждого магазина отдельно. Для каждого магазина прогнозируемой переменной будет вектор из всевозможных товаров (ARTICLE_ID), которые имеются в обучающей или тестовой выборке, причем пропущенные значения заполняются нулями. Оставшиеся признаки (число посетителей магазина, наличие акции на товар и т д) учитываются линейно. Т е модель может быть записанав виде:\n",
        "$$\n",
        "y = f(x_1)+w^Tx_2 + \\epsilon,\n",
        "$$\n",
        "где $x_1$ это лаговые значения целевой переменной, $f$ - нейронная сеть, $x_2$ - вектор оставшихся признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyTCO9UimuYP"
      },
      "source": [
        "Заполним отсутствующие значение нулями."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T4wV_cbV7Cw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNKNarpu2jiS"
      },
      "source": [
        "articles = {}\n",
        "for store in range(1,55):\n",
        "  articles[store]=list(set(df_submission[df_submission.STORE_ID==store].ARTICLE_ID.unique()).union(set(df_train[df_train.STORE_ID==store].ARTICLE_ID.unique())))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opc_syWMl2o_"
      },
      "source": [
        "date = (np.array('2017-06-01', dtype=np.datetime64) + np.arange(61)).astype(str)\n",
        "res = None\n",
        "for store in df_submission.STORE_ID.unique():\n",
        "  if res is None:\n",
        "    res = list( product(date,[store],articles[store] ))\n",
        "  else:\n",
        "    res.extend( list( product(date,[store],articles[store] )) )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEytrA451wDD"
      },
      "source": [
        "res = pd.DataFrame(res,columns = ['DAY_ID','STORE_ID','ARTICLE_ID'])\n",
        "res.sort_values(by = ['DAY_ID','STORE_ID','ARTICLE_ID'],inplace=True)\n",
        "res = pd.merge(res,df_train.drop(['SALES_COUNT','IS_HOLIDAY','WEEKDAY'],axis=1),how='outer',on = ['DAY_ID','STORE_ID','ARTICLE_ID'])\n",
        "res = pd.merge(res,df_sales_count[df_sales_count.DAY_ID<='2017-07-31'],how='outer')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYJMfBYEcKHp"
      },
      "source": [
        "res['IS_HOLIDAY'] = res['DAY_ID'].apply(lambda x: x in df_holidays['DAY_ID'].values)\n",
        "res['WEEKDAY'] = res['DAY_ID'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d').weekday())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNuRlVFrpm02"
      },
      "source": [
        "res.fillna(0.,inplace=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hUyfhx3nuyq"
      },
      "source": [
        "Создадим класс, который воспроизводит описанную выше модель."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kybza7Vei12C"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, pred_len,num_layers,dropout=0.):\n",
        "      super().__init__()\n",
        "\n",
        "      self.input_size=input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.pred_len=pred_len\n",
        "      self.output_size=output_size\n",
        "\n",
        "      self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,num_layers=num_layers,dropout=dropout,batch_first=True)\n",
        "      self.linear = nn.Linear(hidden_size*num_layers*2, output_size*pred_len)\n",
        "\n",
        "      self.actions = nn.Parameter(torch.zeros(output_size).to(device),requires_grad = True)\n",
        "      self.actions.data.uniform_(-1/output_size, 1/output_size)\n",
        "\n",
        "      self.holidays = nn.Parameter(torch.zeros(output_size).to(device),requires_grad = True)\n",
        "      self.holidays.data.uniform_(-1/output_size, 1/output_size)\n",
        "\n",
        "      self.weekdays = nn.Parameter(torch.zeros(7*output_size).to(device),requires_grad = True)\n",
        "      self.weekdays.data.uniform_(-1/7/output_size, 1/7/output_size)\n",
        "\n",
        "      self.sales = nn.Parameter(torch.zeros(output_size).to(device),requires_grad = True)\n",
        "      self.sales.data.uniform_(-1/output_size, 1/output_size)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input_seq,actions,weekdays,sales,holidays):\n",
        "      _,(h_n,c_n) = self.lstm(input_seq)\n",
        "      res = torch.cat([h_n,c_n])\n",
        "      res = torch.transpose(res,0,1)\n",
        "      res = res.reshape(res.shape[0],-1)\n",
        "      return (self.linear(res)).reshape(-1,self.pred_len,self.output_size)+self.actions[actions]*(actions!=0)+self.holidays[holidays]*(holidays!=0)+self.weekdays[weekdays]+sales*self.sales"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn09XHbwn77L"
      },
      "source": [
        "Создадим функция, которая подготавливает данные для модели в нужном формате"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppax1_yffyDg"
      },
      "source": [
        "def inout_seq(TS,A,We,S,H,train_len,pred_len):\n",
        "  N = TS.shape[0]\n",
        "  X,y,act,week,s,h = [],[],[],[],[],[]\n",
        "  for i in range(train_len,N-pred_len):\n",
        "    \n",
        "    X.append(np.concatenate([ TS[i-train_len:i],S[i-train_len:i,[0]] ],axis=1) )\n",
        "    y.append(TS[i:i+pred_len])\n",
        "    act.append(A[i:i+pred_len])\n",
        "    week.append(We[i:i+pred_len])\n",
        "    s.append(S[i:i+pred_len])\n",
        "    h.append(H[i:i+pred_len])\n",
        "\n",
        "  return np.stack(X),np.stack(y),np.stack(act),np.stack(week),np.stack(s),np.stack(h)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPT0NOnn4Xtu"
      },
      "source": [
        "pd.options.mode.chained_assignment = None\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3adEk9oodLb"
      },
      "source": [
        "Зафиксируем параметры, которые были подобраны экспериментально"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AY8qxic4Y9l"
      },
      "source": [
        "train_len = 7\n",
        "pred_len = 15\n",
        "bs = 3\n",
        "n_epoches = 50\n",
        "lr = 1e-3\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "hidden_size = 100"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0bHQDsAqVN8"
      },
      "source": [
        "Тренировочный цикл"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC5SFNlVBf0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a4df4a-3118-4865-dbff-2c7d30c7c470"
      },
      "source": [
        "rmse_dict = {}\n",
        "se = None\n",
        "for store in res.STORE_ID.unique():\n",
        "  ds = res[res.STORE_ID==store]\n",
        "  ds.sort_values(by=['DAY_ID','ARTICLE_ID'],inplace=True)\n",
        "\n",
        "  ids = ds.ARTICLE_ID.unique()\n",
        "  N_items = ids.shape[0]\n",
        "  id_int = {ids[i]:i for i in range(N_items)}\n",
        "  int_id = {i:ids[i] for i in range(N_items)}\n",
        "\n",
        "  ds['ind'] = ds['ARTICLE_ID'].apply(lambda x: id_int[x])\n",
        "  ds['WEEKDAY'] = ds['WEEKDAY']*N_items+ds['ind']\n",
        "  ds['IS_ACTION'] = ds['IS_ACTION']*ds['ind']\n",
        "  ds['IS_HOLIDAY'] = ds['IS_HOLIDAY']*ds['ind']\n",
        "\n",
        "\n",
        "  TS = ds.SALES.values.reshape(-1,N_items)\n",
        "\n",
        "  A = ds.IS_ACTION.values.reshape(-1,N_items)\n",
        "  We = ds.WEEKDAY.values.reshape(-1,N_items)\n",
        "  S = ds.SALES_COUNT.values.reshape(-1,N_items)\n",
        "  H = ds.IS_HOLIDAY.values.reshape(-1,N_items)\n",
        "  \n",
        "  X,y,A,We,S,H = inout_seq(TS,A,We,S,H,train_len,pred_len)\n",
        "\n",
        "  X,y,A,We,S,H = from_numpy(X).to(device).float(),from_numpy(y).to(device).float(),from_numpy(A).to(device).long(),from_numpy(We).to(device).long(), \\\n",
        "  from_numpy(S).to(device).float(),from_numpy(H).to(device).long()\n",
        "\n",
        "  X_train,y_train,A_train,We_train,S_train,H_train = X[:-1],y[:-1],A[:-1],We[:-1],S[:-1],H[:-1]\n",
        "\n",
        "  X_val,y_val,A_val,We_val,S_val,H_val = X[[-1]],y[[-1]],A[[-1]],We[[-1]],S[[-1]],H[[-1]]\n",
        "\n",
        "  model = LSTM(input_size=N_items+1, hidden_size=hidden_size, output_size=N_items, pred_len=pred_len,num_layers=num_layers,dropout=dropout).to(device)\n",
        "  opt = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "  N = X_train.shape[0]\n",
        "  crit = nn.MSELoss()\n",
        "  print(\"Store #{}\".format(store))\n",
        "  model.eval()\n",
        "  preds = model(X_val,A_val,We_val,S_val,H_val)\n",
        "  print('Epoch: {}, RMSE test: {}, R2 test: {}'.format(0, (((preds[y_val!=0]-y_val[y_val!=0])**2).mean()**0.5).item() ,\n",
        "                                              r2_score(y_val[y_val!=0].cpu().detach().numpy(),preds[y_val!=0].cpu().detach().numpy() ) ) )\n",
        "  print('\\n')\n",
        "\n",
        "  for epoch in range(n_epoches):\n",
        "    model.train()\n",
        "    inds = torch.randperm(N).to(device)\n",
        "    for i in range(N//bs):\n",
        "      opt.zero_grad()\n",
        "      X_batch,y_batch,A_batch,We_batch,S_batch,H_batch = X_train[inds[i*bs:(i+1)*bs]],y_train[inds[i*bs:(i+1)*bs]],A_train[inds[i*bs:(i+1)*bs]],We_train[inds[i*bs:(i+1)*bs]], \\\n",
        "      S_train[inds[i*bs:(i+1)*bs]], H_train[inds[i*bs:(i+1)*bs]]\n",
        "\n",
        "      preds = model(X_batch,A_batch,We_batch,S_batch,H_batch)\n",
        "      loss = crit(preds*(y_batch!=0),y_batch)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "    if epoch%(n_epoches//2)==0 or epoch==n_epoches-1:\n",
        "      model.eval()\n",
        "      preds = model(X_train,A_train,We_train,S_train,H_train)\n",
        "      rmse = ( ((preds-y_train)**2)[y_train!=0].mean()**0.5).item()\n",
        "\n",
        "      print('Epoch: {}, RMSE train: {}, R2 train: {}'.format(epoch+1, rmse ,\n",
        "                                                r2_score(y_train[y_train!=0].cpu().detach().numpy(),preds[y_train!=0].cpu().detach().numpy() ) ) )\n",
        "      \n",
        "      preds = model(X_val,A_val,We_val,S_val,H_val)\n",
        "      rmse = ( ((preds-y_val)**2)[y_val!=0].mean()**0.5).item()\n",
        "      print('Epoch: {}, RMSE test: {}, R2 test: {}'.format(epoch+1, rmse ,\n",
        "                                                r2_score(y_val[y_val!=0].cpu().detach().numpy(),preds[y_val!=0].cpu().detach().numpy() ) ) )\n",
        "      print('\\n')\n",
        "\n",
        "  model.eval()\n",
        "  preds = model(X_val,A_val,We_val,S_val,H_val)\n",
        "  rmse_dict[store]=(((preds-y_val)**2)[y_val!=0].mean()**0.5).item()\n",
        "  if se is None:\n",
        "    se = ((preds-y_val)**2)[y_val!=0]\n",
        "  else:\n",
        "    se = torch.cat([se,((preds-y_val)**2)[y_val!=0]])\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Store #1\n",
            "Epoch: 0, RMSE test: 10.61642074584961, R2 test: -0.34014841316683175\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 8.568536758422852, R2 train: 0.333652645106436\n",
            "Epoch: 1, RMSE test: 7.260906219482422, R2 test: 0.3731288019341401\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 6.623193264007568, R2 train: 0.6018723933492713\n",
            "Epoch: 26, RMSE test: 5.538658142089844, R2 test: 0.6352412086724784\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 6.315693378448486, R2 train: 0.6379825884267798\n",
            "Epoch: 50, RMSE test: 5.5644001960754395, R2 test: 0.6318427475745136\n",
            "\n",
            "\n",
            "Store #2\n",
            "Epoch: 0, RMSE test: 14.637755393981934, R2 test: -0.2717485078474098\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 11.066709518432617, R2 train: 0.3080476336557203\n",
            "Epoch: 1, RMSE test: 10.840424537658691, R2 test: 0.3024990534310372\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 8.062589645385742, R2 train: 0.6327276202893678\n",
            "Epoch: 26, RMSE test: 8.681868553161621, R2 test: 0.552617856209656\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 7.779990196228027, R2 train: 0.6580227214605232\n",
            "Epoch: 50, RMSE test: 8.291024208068848, R2 test: 0.5919920706658359\n",
            "\n",
            "\n",
            "Store #3\n",
            "Epoch: 0, RMSE test: 35.081207275390625, R2 test: -0.18709241606194715\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 25.377674102783203, R2 train: 0.30057385149802684\n",
            "Epoch: 1, RMSE test: 27.74885368347168, R2 test: 0.25727926157880143\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 13.148151397705078, R2 train: 0.812255327003894\n",
            "Epoch: 26, RMSE test: 16.275009155273438, R2 test: 0.7445076242507135\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 13.019867897033691, R2 train: 0.8159010437211207\n",
            "Epoch: 50, RMSE test: 16.035768508911133, R2 test: 0.7519638441982142\n",
            "\n",
            "\n",
            "Store #4\n",
            "Epoch: 0, RMSE test: 12.373092651367188, R2 test: -0.31607957452827495\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 8.388066291809082, R2 train: 0.34436137553895474\n",
            "Epoch: 1, RMSE test: 8.964452743530273, R2 test: 0.3091667151075197\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 5.921860694885254, R2 train: 0.6732186918378512\n",
            "Epoch: 26, RMSE test: 6.52202844619751, R2 test: 0.6343285650603971\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 5.742773532867432, R2 train: 0.6926846710414003\n",
            "Epoch: 50, RMSE test: 6.405404567718506, R2 test: 0.6472891719210926\n",
            "\n",
            "\n",
            "Store #5\n",
            "Epoch: 0, RMSE test: 10.533586502075195, R2 test: -0.35075901010558463\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 6.987346172332764, R2 train: 0.3426337877468284\n",
            "Epoch: 1, RMSE test: 7.396938800811768, R2 test: 0.3339153345258834\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 5.441444396972656, R2 train: 0.6013321528556689\n",
            "Epoch: 26, RMSE test: 5.98813009262085, R2 test: 0.5634763596738739\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 5.178347110748291, R2 train: 0.6389518464688725\n",
            "Epoch: 50, RMSE test: 5.943213939666748, R2 test: 0.5700003496770212\n",
            "\n",
            "\n",
            "Store #6\n",
            "Epoch: 0, RMSE test: 16.67597198486328, R2 test: -0.25507005215850254\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 10.568164825439453, R2 train: 0.3504595249272151\n",
            "Epoch: 1, RMSE test: 12.782135009765625, R2 test: 0.262618148674853\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 7.327221870422363, R2 train: 0.6877619838885818\n",
            "Epoch: 26, RMSE test: 10.008808135986328, R2 test: 0.5478834744453773\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 6.992701053619385, R2 train: 0.7156213419102984\n",
            "Epoch: 50, RMSE test: 9.680475234985352, R2 test: 0.577059736026962\n",
            "\n",
            "\n",
            "Store #7\n",
            "Epoch: 0, RMSE test: 19.401996612548828, R2 test: -0.22726209280215093\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 15.078536033630371, R2 train: 0.31255909985796604\n",
            "Epoch: 1, RMSE test: 14.825815200805664, R2 test: 0.28339193469386226\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 7.600101947784424, R2 train: 0.8253551316431469\n",
            "Epoch: 26, RMSE test: 7.935168266296387, R2 test: 0.7947151829475139\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 7.550251007080078, R2 train: 0.8276386952104458\n",
            "Epoch: 50, RMSE test: 8.04024887084961, R2 test: 0.7892422966219569\n",
            "\n",
            "\n",
            "Store #8\n",
            "Epoch: 0, RMSE test: 19.88435173034668, R2 test: -0.24418259832296063\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 13.984649658203125, R2 train: 0.36525664986195694\n",
            "Epoch: 1, RMSE test: 14.513453483581543, R2 test: 0.3371690203948109\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 8.036377906799316, R2 train: 0.7903881907163351\n",
            "Epoch: 26, RMSE test: 8.67408561706543, R2 test: 0.7632398080308989\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 7.944366931915283, R2 train: 0.7951605687439962\n",
            "Epoch: 50, RMSE test: 8.534826278686523, R2 test: 0.7707809730399634\n",
            "\n",
            "\n",
            "Store #9\n",
            "Epoch: 0, RMSE test: 16.84615135192871, R2 test: -0.2752404527633239\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 11.620277404785156, R2 train: 0.35712813153163314\n",
            "Epoch: 1, RMSE test: 12.583115577697754, R2 test: 0.2885130199971748\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 8.211584091186523, R2 train: 0.6789702326241762\n",
            "Epoch: 26, RMSE test: 9.779481887817383, R2 test: 0.5702436539202801\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 8.109118461608887, R2 train: 0.6869319368593786\n",
            "Epoch: 50, RMSE test: 9.773771286010742, R2 test: 0.5707453693155147\n",
            "\n",
            "\n",
            "Store #10\n",
            "Epoch: 0, RMSE test: 16.928163528442383, R2 test: -0.09228623152020399\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 7.285881996154785, R2 train: 0.26622816756054757\n",
            "Epoch: 1, RMSE test: 15.538678169250488, R2 test: 0.07966712894507677\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 5.350160598754883, R2 train: 0.6043324897430689\n",
            "Epoch: 26, RMSE test: 14.44846248626709, R2 test: 0.20428044281860047\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 5.175726890563965, R2 train: 0.6297121478655696\n",
            "Epoch: 50, RMSE test: 14.229873657226562, R2 test: 0.2281748428579643\n",
            "\n",
            "\n",
            "Store #11\n",
            "Epoch: 0, RMSE test: 22.442338943481445, R2 test: -0.20293188452799482\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 17.105030059814453, R2 train: 0.32161155303840394\n",
            "Epoch: 1, RMSE test: 17.17586326599121, R2 test: 0.29540097989326053\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 10.103643417358398, R2 train: 0.7633062209571566\n",
            "Epoch: 26, RMSE test: 12.144749641418457, R2 test: 0.647724850490578\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 9.988606452941895, R2 train: 0.7686653840056539\n",
            "Epoch: 50, RMSE test: 12.110487937927246, R2 test: 0.6497096614266382\n",
            "\n",
            "\n",
            "Store #12\n",
            "Epoch: 0, RMSE test: 20.56433868408203, R2 test: -0.06920825471468617\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 7.109662055969238, R2 train: 0.3206433801860361\n",
            "Epoch: 1, RMSE test: 19.23297882080078, R2 test: 0.06475404102612403\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 5.763973712921143, R2 train: 0.5534769646372899\n",
            "Epoch: 26, RMSE test: 18.223674774169922, R2 test: 0.16033770954591953\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 5.505248069763184, R2 train: 0.5926631730540337\n",
            "Epoch: 50, RMSE test: 17.530467987060547, R2 test: 0.22300215511926436\n",
            "\n",
            "\n",
            "Store #13\n",
            "Epoch: 0, RMSE test: 12.689920425415039, R2 test: -0.18308986667447558\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 12.16330337524414, R2 train: 0.13324022166332083\n",
            "Epoch: 1, RMSE test: 10.686436653137207, R2 test: 0.16099267327408595\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 10.722222328186035, R2 train: 0.3264570125247207\n",
            "Epoch: 26, RMSE test: 9.594283103942871, R2 test: 0.323722533353607\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 10.414695739746094, R2 train: 0.36453899820865643\n",
            "Epoch: 50, RMSE test: 9.413471221923828, R2 test: 0.3489722870837345\n",
            "\n",
            "\n",
            "Store #14\n",
            "Epoch: 0, RMSE test: 35.09578323364258, R2 test: -0.029257782459764625\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 12.591926574707031, R2 train: 0.1530836623571339\n",
            "Epoch: 1, RMSE test: 34.11537170410156, R2 test: 0.02744428860603021\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 10.779258728027344, R2 train: 0.3793683647661862\n",
            "Epoch: 26, RMSE test: 32.89174270629883, R2 test: 0.09595913104296505\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 10.468780517578125, R2 train: 0.41460587501992174\n",
            "Epoch: 50, RMSE test: 32.59292984008789, R2 test: 0.11231062092895061\n",
            "\n",
            "\n",
            "Store #15\n",
            "Epoch: 0, RMSE test: 9.203929901123047, R2 test: -0.4268042723556016\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 6.701855182647705, R2 train: 0.36796457283547623\n",
            "Epoch: 1, RMSE test: 6.054915428161621, R2 test: 0.38250429075561243\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 5.313277244567871, R2 train: 0.6027386930802943\n",
            "Epoch: 26, RMSE test: 5.154664039611816, R2 test: 0.5524738144106804\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 5.090511798858643, R2 train: 0.6353516343070549\n",
            "Epoch: 50, RMSE test: 5.117465972900391, R2 test: 0.5589095036769711\n",
            "\n",
            "\n",
            "Store #16\n",
            "Epoch: 0, RMSE test: 17.600757598876953, R2 test: -0.08160625798378529\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 23.85126495361328, R2 train: 0.030518433510835385\n",
            "Epoch: 1, RMSE test: 16.408418655395508, R2 test: 0.059973959339842176\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 22.039745330810547, R2 train: 0.17219161327945154\n",
            "Epoch: 26, RMSE test: 16.214120864868164, R2 test: 0.0821043875379508\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 21.260543823242188, R2 train: 0.22969016172657153\n",
            "Epoch: 50, RMSE test: 15.702065467834473, R2 test: 0.1391647973632003\n",
            "\n",
            "\n",
            "Store #17\n",
            "Epoch: 0, RMSE test: 18.620695114135742, R2 test: -0.2146309769022805\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 12.570525169372559, R2 train: 0.2704483212425437\n",
            "Epoch: 1, RMSE test: 15.069726943969727, R2 test: 0.20445755676946975\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 9.3765287399292, R2 train: 0.5940866245803703\n",
            "Epoch: 26, RMSE test: 12.635393142700195, R2 test: 0.4407188237104944\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 9.191485404968262, R2 train: 0.6099497145994227\n",
            "Epoch: 50, RMSE test: 12.571565628051758, R2 test: 0.4463550546604387\n",
            "\n",
            "\n",
            "Store #18\n",
            "Epoch: 0, RMSE test: 10.833233833312988, R2 test: -0.33715194125728676\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 8.04297924041748, R2 train: 0.33083776221285555\n",
            "Epoch: 1, RMSE test: 7.745391368865967, R2 test: 0.3164800418851139\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 5.975700855255127, R2 train: 0.6306183693103353\n",
            "Epoch: 26, RMSE test: 6.054371356964111, R2 test: 0.5823595216383948\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 5.614461898803711, R2 train: 0.6739277394333694\n",
            "Epoch: 50, RMSE test: 6.054848670959473, R2 test: 0.5822936164103303\n",
            "\n",
            "\n",
            "Store #19\n",
            "Epoch: 0, RMSE test: 14.781524658203125, R2 test: -0.21773011163959488\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 11.203387260437012, R2 train: 0.2638847127521332\n",
            "Epoch: 1, RMSE test: 11.608526229858398, R2 test: 0.24895360936104638\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 6.808208465576172, R2 train: 0.7281603493153699\n",
            "Epoch: 26, RMSE test: 8.332925796508789, R2 test: 0.6130030394612013\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 6.663217544555664, R2 train: 0.7396155305473024\n",
            "Epoch: 50, RMSE test: 8.23302173614502, R2 test: 0.6222268102282915\n",
            "\n",
            "\n",
            "Store #20\n",
            "Epoch: 0, RMSE test: 30.972713470458984, R2 test: -0.07155897721075188\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 12.9837064743042, R2 train: 0.2577428424799777\n",
            "Epoch: 1, RMSE test: 28.730989456176758, R2 test: 0.07794089616996525\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 9.42794132232666, R2 train: 0.6086271293256676\n",
            "Epoch: 26, RMSE test: 26.521181106567383, R2 test: 0.21432431634496785\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 9.217767715454102, R2 train: 0.6258820122463693\n",
            "Epoch: 50, RMSE test: 26.407960891723633, R2 test: 0.2210180799487883\n",
            "\n",
            "\n",
            "Store #21\n",
            "Epoch: 0, RMSE test: 28.449459075927734, R2 test: -0.06937715952826595\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 15.867526054382324, R2 train: 0.14388329556985202\n",
            "Epoch: 1, RMSE test: 26.623981475830078, R2 test: 0.06345438034030904\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 12.98754596710205, R2 train: 0.42645337314493714\n",
            "Epoch: 26, RMSE test: 24.68092155456543, R2 test: 0.195167231793141\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 12.618672370910645, R2 train: 0.45857056888675685\n",
            "Epoch: 50, RMSE test: 24.39988899230957, R2 test: 0.21339165851571118\n",
            "\n",
            "\n",
            "Store #22\n",
            "Epoch: 0, RMSE test: 14.492055892944336, R2 test: -0.12995182314456022\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 8.189718246459961, R2 train: 0.20518572502829013\n",
            "Epoch: 1, RMSE test: 12.959746360778809, R2 test: 0.09636525168155341\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 6.110987186431885, R2 train: 0.5574621374126525\n",
            "Epoch: 26, RMSE test: 11.688909530639648, R2 test: 0.2648973129725317\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 5.784843444824219, R2 train: 0.6034381578172077\n",
            "Epoch: 50, RMSE test: 11.906021118164062, R2 test: 0.23733600659459064\n",
            "\n",
            "\n",
            "Store #23\n",
            "Epoch: 0, RMSE test: 12.860980987548828, R2 test: -0.15442104895900677\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 10.903464317321777, R2 train: 0.1521918329309765\n",
            "Epoch: 1, RMSE test: 11.08360481262207, R2 test: 0.14261075717669403\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 6.796839237213135, R2 train: 0.6705552960970409\n",
            "Epoch: 26, RMSE test: 7.317493438720703, R2 test: 0.62628482654371\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 6.678767204284668, R2 train: 0.6819018379668917\n",
            "Epoch: 50, RMSE test: 7.248774528503418, R2 test: 0.6332710642158133\n",
            "\n",
            "\n",
            "Store #24\n",
            "Epoch: 0, RMSE test: 16.437551498413086, R2 test: -0.30151818014686116\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 10.544060707092285, R2 train: 0.4165700213589143\n",
            "Epoch: 1, RMSE test: 11.51821517944336, R2 test: 0.36093304287895955\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 6.940400123596191, R2 train: 0.747220400455469\n",
            "Epoch: 26, RMSE test: 8.544687271118164, R2 test: 0.6483032407335377\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 6.914959907531738, R2 train: 0.7490701294190052\n",
            "Epoch: 50, RMSE test: 8.593428611755371, R2 test: 0.6442794186240515\n",
            "\n",
            "\n",
            "Store #25\n",
            "Epoch: 0, RMSE test: 10.621712684631348, R2 test: -0.30749288064078995\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 7.242029190063477, R2 train: 0.28241564748866377\n",
            "Epoch: 1, RMSE test: 7.757540225982666, R2 test: 0.3025736715524675\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 5.542982578277588, R2 train: 0.5796224916248194\n",
            "Epoch: 26, RMSE test: 5.889212131500244, R2 test: 0.5980568671805545\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 5.223285675048828, R2 train: 0.6267155320368086\n",
            "Epoch: 50, RMSE test: 5.992099761962891, R2 test: 0.5838897866636863\n",
            "\n",
            "\n",
            "Store #26\n",
            "Epoch: 0, RMSE test: 10.388131141662598, R2 test: -0.19389679900860113\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 8.019085884094238, R2 train: 0.1467348698743326\n",
            "Epoch: 1, RMSE test: 8.794370651245117, R2 test: 0.14433944905983276\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 6.555884838104248, R2 train: 0.42970852994974684\n",
            "Epoch: 26, RMSE test: 7.211548805236816, R2 test: 0.424627504587613\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 6.083189010620117, R2 train: 0.5089826197376632\n",
            "Epoch: 50, RMSE test: 7.222065448760986, R2 test: 0.42294813606606385\n",
            "\n",
            "\n",
            "Store #27\n",
            "Epoch: 0, RMSE test: 17.299306869506836, R2 test: -0.2507454623501213\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 11.506583213806152, R2 train: 0.33756641735297843\n",
            "Epoch: 1, RMSE test: 12.964707374572754, R2 test: 0.2975150754034436\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 7.248443603515625, R2 train: 0.7371311755833312\n",
            "Epoch: 26, RMSE test: 9.899368286132812, R2 test: 0.5904315202606749\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 7.111293315887451, R2 train: 0.7469847067206918\n",
            "Epoch: 50, RMSE test: 9.780084609985352, R2 test: 0.6002423577904632\n",
            "\n",
            "\n",
            "Store #28\n",
            "Epoch: 0, RMSE test: 16.52349281311035, R2 test: -0.2696948106249253\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 13.557350158691406, R2 train: 0.2430918691470605\n",
            "Epoch: 1, RMSE test: 12.626130104064941, R2 test: 0.25862802304646826\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 10.407267570495605, R2 train: 0.5539670210567075\n",
            "Epoch: 26, RMSE test: 10.59427261352539, R2 test: 0.4780391247902974\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 9.929095268249512, R2 train: 0.5940122708661197\n",
            "Epoch: 50, RMSE test: 10.342674255371094, R2 test: 0.5025364195590798\n",
            "\n",
            "\n",
            "Store #29\n",
            "Epoch: 0, RMSE test: 13.960423469543457, R2 test: -0.29465553732994065\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 9.184747695922852, R2 train: 0.32677457778286567\n",
            "Epoch: 1, RMSE test: 10.42190170288086, R2 test: 0.27847561886486216\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 6.914121150970459, R2 train: 0.6184952418427947\n",
            "Epoch: 26, RMSE test: 8.769791603088379, R2 test: 0.48910030713659614\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 6.612399578094482, R2 train: 0.6510653216014859\n",
            "Epoch: 50, RMSE test: 8.615588188171387, R2 test: 0.506909195065634\n",
            "\n",
            "\n",
            "Store #30\n",
            "Epoch: 0, RMSE test: 28.442182540893555, R2 test: -0.03331646225122964\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 40.35060119628906, R2 train: 0.014231014966436084\n",
            "Epoch: 1, RMSE test: 27.67028045654297, R2 test: 0.022009501155050626\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 37.36419677734375, R2 train: 0.15474756137939694\n",
            "Epoch: 26, RMSE test: 28.641565322875977, R2 test: -0.04785452454720418\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 36.71586990356445, R2 train: 0.1838259529651194\n",
            "Epoch: 50, RMSE test: 27.891677856445312, R2 test: 0.0062965005852683165\n",
            "\n",
            "\n",
            "Store #31\n",
            "Epoch: 0, RMSE test: 42.43986129760742, R2 test: -0.035792330744794265\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 29.576000213623047, R2 train: 0.06434018230716043\n",
            "Epoch: 1, RMSE test: 40.90873718261719, R2 test: 0.03759697290023545\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 24.812175750732422, R2 train: 0.3414802569138896\n",
            "Epoch: 26, RMSE test: 35.763492584228516, R2 test: 0.26446285535117553\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 23.36942481994629, R2 train: 0.41583553978572474\n",
            "Epoch: 50, RMSE test: 34.498695373535156, R2 test: 0.315568307248386\n",
            "\n",
            "\n",
            "Store #32\n",
            "Epoch: 0, RMSE test: 19.21000099182129, R2 test: -0.051896442279484534\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 54.71535873413086, R2 train: 0.006052662786176444\n",
            "Epoch: 1, RMSE test: 18.401180267333984, R2 test: 0.03481745237404965\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 51.462337493896484, R2 train: 0.12072687927939307\n",
            "Epoch: 26, RMSE test: 17.926774978637695, R2 test: 0.08394297442119447\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 49.67256546020508, R2 train: 0.18082246757014764\n",
            "Epoch: 50, RMSE test: 17.636859893798828, R2 test: 0.1133328100206058\n",
            "\n",
            "\n",
            "Store #33\n",
            "Epoch: 0, RMSE test: 33.604400634765625, R2 test: -0.04064156097558924\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 23.195173263549805, R2 train: 0.06763022347713588\n",
            "Epoch: 1, RMSE test: 32.40659713745117, R2 test: 0.03222173613566848\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 20.28985595703125, R2 train: 0.2865707963912725\n",
            "Epoch: 26, RMSE test: 28.580394744873047, R2 test: 0.24725940949430047\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 19.504579544067383, R2 train: 0.34072579540244885\n",
            "Epoch: 50, RMSE test: 27.149932861328125, R2 test: 0.32072376091597143\n",
            "\n",
            "\n",
            "Store #34\n",
            "Epoch: 0, RMSE test: 13.08565616607666, R2 test: -0.26557495002269604\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 8.334344863891602, R2 train: 0.3889613180937448\n",
            "Epoch: 1, RMSE test: 9.607873916625977, R2 test: 0.3177375385304191\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 6.427555561065674, R2 train: 0.6365728094957644\n",
            "Epoch: 26, RMSE test: 8.501758575439453, R2 test: 0.46578702146538753\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 6.21019172668457, R2 train: 0.6607375181006621\n",
            "Epoch: 50, RMSE test: 8.461666107177734, R2 test: 0.4708135240304012\n",
            "\n",
            "\n",
            "Store #35\n",
            "Epoch: 0, RMSE test: 10.967992782592773, R2 test: -0.25990651175663104\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 8.48173713684082, R2 train: 0.2337017684530025\n",
            "Epoch: 1, RMSE test: 8.548742294311523, R2 test: 0.2346000202609585\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 5.899631977081299, R2 train: 0.6292526453812564\n",
            "Epoch: 26, RMSE test: 6.357038974761963, R2 test: 0.576753085756424\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 5.61175537109375, R2 train: 0.6645516286224251\n",
            "Epoch: 50, RMSE test: 6.400051593780518, R2 test: 0.5710062368533705\n",
            "\n",
            "\n",
            "Store #36\n",
            "Epoch: 0, RMSE test: 15.50168514251709, R2 test: -0.21571220771611932\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 10.674784660339355, R2 train: 0.2560778096564239\n",
            "Epoch: 1, RMSE test: 12.442538261413574, R2 test: 0.21676702673292325\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 8.386103630065918, R2 train: 0.5408763084658031\n",
            "Epoch: 26, RMSE test: 9.953414916992188, R2 test: 0.4987929184124994\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 8.112650871276855, R2 train: 0.57033018304384\n",
            "Epoch: 50, RMSE test: 9.872393608093262, R2 test: 0.506919452957891\n",
            "\n",
            "\n",
            "Store #37\n",
            "Epoch: 0, RMSE test: 16.01347541809082, R2 test: -0.1959556635663764\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 10.807066917419434, R2 train: 0.2825163359805509\n",
            "Epoch: 1, RMSE test: 13.003398895263672, R2 test: 0.211398451306405\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 8.135558128356934, R2 train: 0.5933965330457951\n",
            "Epoch: 26, RMSE test: 10.809487342834473, R2 test: 0.4550532975010877\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 7.864712715148926, R2 train: 0.6200188429480418\n",
            "Epoch: 50, RMSE test: 10.515562057495117, R2 test: 0.48428606046889955\n",
            "\n",
            "\n",
            "Store #38\n",
            "Epoch: 0, RMSE test: 29.526107788085938, R2 test: -0.053121225059465704\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 43.19212341308594, R2 train: 0.028601634134080123\n",
            "Epoch: 1, RMSE test: 27.937822341918945, R2 test: 0.057131607933471606\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 40.081787109375, R2 train: 0.16346825004888754\n",
            "Epoch: 26, RMSE test: 25.716171264648438, R2 test: 0.20112545529440362\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 39.484352111816406, R2 train: 0.18822000880663292\n",
            "Epoch: 50, RMSE test: 25.92703628540039, R2 test: 0.18797074820231574\n",
            "\n",
            "\n",
            "Store #39\n",
            "Epoch: 0, RMSE test: 49.01185607910156, R2 test: -0.030073930554001205\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 39.44523620605469, R2 train: 0.040510071562693706\n",
            "Epoch: 1, RMSE test: 47.61724090576172, R2 test: 0.027712730134579422\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 35.72150802612305, R2 train: 0.21311579495520938\n",
            "Epoch: 26, RMSE test: 43.95161437988281, R2 test: 0.17164622224024062\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 35.41183853149414, R2 train: 0.22669952943546778\n",
            "Epoch: 50, RMSE test: 43.82771301269531, R2 test: 0.17630994993531046\n",
            "\n",
            "\n",
            "Store #40\n",
            "Epoch: 0, RMSE test: 46.34633255004883, R2 test: -0.0435892010339507\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 32.82563400268555, R2 train: 0.06744440794574069\n",
            "Epoch: 1, RMSE test: 44.58542251586914, R2 test: 0.034205679027787594\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 28.622112274169922, R2 train: 0.2909908556313774\n",
            "Epoch: 26, RMSE test: 42.1358642578125, R2 test: 0.13741347825240158\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 27.612520217895508, R2 train: 0.3401267312490408\n",
            "Epoch: 50, RMSE test: 41.940940856933594, R2 test: 0.14537588946750446\n",
            "\n",
            "\n",
            "Store #41\n",
            "Epoch: 0, RMSE test: 34.54759979248047, R2 test: -0.05117422260651305\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 25.377819061279297, R2 train: 0.06667359945271534\n",
            "Epoch: 1, RMSE test: 32.81277084350586, R2 test: 0.051745933715710235\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 22.8023624420166, R2 train: 0.2464974652801939\n",
            "Epoch: 26, RMSE test: 29.38051414489746, R2 test: 0.239747775466281\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 22.165142059326172, R2 train: 0.28802290702043776\n",
            "Epoch: 50, RMSE test: 29.10886573791504, R2 test: 0.2537412074552361\n",
            "\n",
            "\n",
            "Store #42\n",
            "Epoch: 0, RMSE test: 21.08845329284668, R2 test: -0.10007224576911455\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 12.161635398864746, R2 train: 0.22123490342997698\n",
            "Epoch: 1, RMSE test: 19.031103134155273, R2 test: 0.10409986695233886\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 8.29610538482666, R2 train: 0.6376142696328091\n",
            "Epoch: 26, RMSE test: 15.663725852966309, R2 test: 0.3930934708873943\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 8.2302827835083, R2 train: 0.6433420351084982\n",
            "Epoch: 50, RMSE test: 15.661861419677734, R2 test: 0.39323786900476954\n",
            "\n",
            "\n",
            "Store #43\n",
            "Epoch: 0, RMSE test: 24.305126190185547, R2 test: -0.13748855819310668\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 21.513830184936523, R2 train: 0.16789406267064888\n",
            "Epoch: 1, RMSE test: 20.666629791259766, R2 test: 0.17758599937473096\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 14.735170364379883, R2 train: 0.6096505891667503\n",
            "Epoch: 26, RMSE test: 14.445948600769043, R2 test: 0.5981690442181233\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 14.606403350830078, R2 train: 0.6164431076094388\n",
            "Epoch: 50, RMSE test: 14.450540542602539, R2 test: 0.5979135569289387\n",
            "\n",
            "\n",
            "Store #44\n",
            "Epoch: 0, RMSE test: 43.46345901489258, R2 test: -0.16868474318151527\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 32.19598388671875, R2 train: 0.2865421127824248\n",
            "Epoch: 1, RMSE test: 34.521724700927734, R2 test: 0.26271780991820504\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 20.06429100036621, R2 train: 0.7229152769677829\n",
            "Epoch: 26, RMSE test: 21.292898178100586, R2 test: 0.7195094012595056\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 19.912841796875, R2 train: 0.7270824653319505\n",
            "Epoch: 50, RMSE test: 21.282058715820312, R2 test: 0.719794854401568\n",
            "\n",
            "\n",
            "Store #45\n",
            "Epoch: 0, RMSE test: 37.4511604309082, R2 test: -0.196351878033046\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 25.785634994506836, R2 train: 0.314935612657378\n",
            "Epoch: 1, RMSE test: 29.501386642456055, R2 test: 0.2576422886353177\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 16.813257217407227, R2 train: 0.7087409323168911\n",
            "Epoch: 26, RMSE test: 21.56228256225586, R2 test: 0.6034318456600778\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 16.700756072998047, R2 train: 0.7126256852307791\n",
            "Epoch: 50, RMSE test: 21.491798400878906, R2 test: 0.606020311124563\n",
            "\n",
            "\n",
            "Store #46\n",
            "Epoch: 0, RMSE test: 29.27281379699707, R2 test: -0.20118350861708212\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 21.869863510131836, R2 train: 0.293802989702428\n",
            "Epoch: 1, RMSE test: 22.656417846679688, R2 test: 0.28044683949736526\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 17.178043365478516, R2 train: 0.5643064689976883\n",
            "Epoch: 26, RMSE test: 18.604263305664062, R2 test: 0.5148173005629605\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 16.87220573425293, R2 train: 0.5796824759078477\n",
            "Epoch: 50, RMSE test: 18.414644241333008, R2 test: 0.5246570309256136\n",
            "\n",
            "\n",
            "Store #47\n",
            "Epoch: 0, RMSE test: 39.08470916748047, R2 test: -0.15434023251193163\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 31.9268741607666, R2 train: 0.2091820408406435\n",
            "Epoch: 1, RMSE test: 32.570796966552734, R2 test: 0.19836476126538194\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 26.812898635864258, R2 train: 0.44223499245042086\n",
            "Epoch: 26, RMSE test: 26.669889450073242, R2 test: 0.46251975096287745\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 26.670072555541992, R2 train: 0.4481614160495436\n",
            "Epoch: 50, RMSE test: 26.670028686523438, R2 test: 0.4625141711486521\n",
            "\n",
            "\n",
            "Store #48\n",
            "Epoch: 0, RMSE test: 26.810073852539062, R2 test: -0.17788045254089369\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 16.83528709411621, R2 train: 0.3264061340492582\n",
            "Epoch: 1, RMSE test: 21.40130043029785, R2 test: 0.24943982032888934\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 12.60852336883545, R2 train: 0.6221794848908371\n",
            "Epoch: 26, RMSE test: 17.418825149536133, R2 test: 0.5027865385349195\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 12.413400650024414, R2 train: 0.633782916192408\n",
            "Epoch: 50, RMSE test: 17.230854034423828, R2 test: 0.5134597626693336\n",
            "\n",
            "\n",
            "Store #49\n",
            "Epoch: 0, RMSE test: 28.715328216552734, R2 test: -0.23470462988686047\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 22.14832305908203, R2 train: 0.31868014535428313\n",
            "Epoch: 1, RMSE test: 21.75797462463379, R2 test: 0.2911203768509376\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 12.09022331237793, R2 train: 0.7969804089738322\n",
            "Epoch: 26, RMSE test: 12.539737701416016, R2 test: 0.7645425537753893\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 12.008110046386719, R2 train: 0.7997287357484164\n",
            "Epoch: 50, RMSE test: 12.426102638244629, R2 test: 0.768790634497807\n",
            "\n",
            "\n",
            "Store #50\n",
            "Epoch: 0, RMSE test: 20.565370559692383, R2 test: -0.23475276978958548\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 11.743326187133789, R2 train: 0.3773872956692582\n",
            "Epoch: 1, RMSE test: 15.776456832885742, R2 test: 0.2733490310824507\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 8.94637393951416, R2 train: 0.6386485394413542\n",
            "Epoch: 26, RMSE test: 12.883964538574219, R2 test: 0.5153748323181744\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 8.644675254821777, R2 train: 0.6626093236556354\n",
            "Epoch: 50, RMSE test: 12.175582885742188, R2 test: 0.5672007674748428\n",
            "\n",
            "\n",
            "Store #51\n",
            "Epoch: 0, RMSE test: 30.046567916870117, R2 test: -0.13567964394068222\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 27.19034194946289, R2 train: 0.14266683148777293\n",
            "Epoch: 1, RMSE test: 26.031845092773438, R2 test: 0.14753616790792357\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 17.088224411010742, R2 train: 0.6613788421409\n",
            "Epoch: 26, RMSE test: 16.896169662475586, R2 test: 0.6408774769450191\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 13.574568748474121, R2 train: 0.7863158165177533\n",
            "Epoch: 50, RMSE test: 13.812931060791016, R2 test: 0.7599852833528589\n",
            "\n",
            "\n",
            "Store #52\n",
            "Epoch: 0, RMSE test: 21.914003372192383, R2 test: -0.25116001826687073\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 13.528099060058594, R2 train: 0.37399038532466655\n",
            "Epoch: 1, RMSE test: 15.937650680541992, R2 test: 0.33821331623544204\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 8.10624885559082, R2 train: 0.7752253645389449\n",
            "Epoch: 26, RMSE test: 10.624277114868164, R2 test: 0.7059181407702326\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 8.028908729553223, R2 train: 0.7794939708369608\n",
            "Epoch: 50, RMSE test: 10.59821605682373, R2 test: 0.7073591197790792\n",
            "\n",
            "\n",
            "Store #53\n",
            "Epoch: 0, RMSE test: 12.719902038574219, R2 test: -0.3183246925967136\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 8.003437995910645, R2 train: 0.3611522443755051\n",
            "Epoch: 1, RMSE test: 9.132997512817383, R2 test: 0.32035605307314075\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 5.650404930114746, R2 train: 0.6815777195190817\n",
            "Epoch: 26, RMSE test: 6.742605686187744, R2 test: 0.6295664096305638\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 5.421359539031982, R2 train: 0.7068697020529874\n",
            "Epoch: 50, RMSE test: 6.710556507110596, R2 test: 0.6330795809691456\n",
            "\n",
            "\n",
            "Store #54\n",
            "Epoch: 0, RMSE test: 66.96697235107422, R2 test: -0.01448028399801693\n",
            "\n",
            "\n",
            "Epoch: 1, RMSE train: 90.59014129638672, R2 train: 0.006051090433851658\n",
            "Epoch: 1, RMSE test: 66.10507202148438, R2 test: 0.011465650075678457\n",
            "\n",
            "\n",
            "Epoch: 26, RMSE train: 83.72134399414062, R2 train: 0.15106468016798325\n",
            "Epoch: 26, RMSE test: 58.63680648803711, R2 test: 0.22220912790029246\n",
            "\n",
            "\n",
            "Epoch: 50, RMSE train: 80.01624298095703, R2 train: 0.22454143480559985\n",
            "Epoch: 50, RMSE test: 55.83620071411133, R2 test: 0.29473247694885973\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6pt32yh4bds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb5b0a3-a8bf-4125-e121-a74d0843d1e8"
      },
      "source": [
        "print(\"RMSE val: {}\".format( (se.mean()**0.5).item() ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE val: 18.754392623901367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqqox9LM5kss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f2bc86-6a06-48e8-ec45-c1412b6b3cb2"
      },
      "source": [
        "print(\"RMSE на валидационной выборке для различных магазинов:\")\n",
        "for key in rmse_dict:\n",
        "  print(\"Store #{}: {}\".format(key,round(rmse_dict[key],3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE на валидационной выборке для различных магазинов:\n",
            "Store #1: 5.564\n",
            "Store #2: 8.291\n",
            "Store #3: 16.036\n",
            "Store #4: 6.405\n",
            "Store #5: 5.943\n",
            "Store #6: 9.68\n",
            "Store #7: 8.04\n",
            "Store #8: 8.535\n",
            "Store #9: 9.774\n",
            "Store #10: 14.23\n",
            "Store #11: 12.11\n",
            "Store #12: 17.53\n",
            "Store #13: 9.413\n",
            "Store #14: 32.593\n",
            "Store #15: 5.117\n",
            "Store #16: 15.702\n",
            "Store #17: 12.572\n",
            "Store #18: 6.055\n",
            "Store #19: 8.233\n",
            "Store #20: 26.408\n",
            "Store #21: 24.4\n",
            "Store #22: 11.906\n",
            "Store #23: 7.249\n",
            "Store #24: 8.593\n",
            "Store #25: 5.992\n",
            "Store #26: 7.222\n",
            "Store #27: 9.78\n",
            "Store #28: 10.343\n",
            "Store #29: 8.616\n",
            "Store #30: 27.892\n",
            "Store #31: 34.499\n",
            "Store #32: 17.637\n",
            "Store #33: 27.15\n",
            "Store #34: 8.462\n",
            "Store #35: 6.4\n",
            "Store #36: 9.872\n",
            "Store #37: 10.516\n",
            "Store #38: 25.927\n",
            "Store #39: 43.828\n",
            "Store #40: 41.941\n",
            "Store #41: 29.109\n",
            "Store #42: 15.662\n",
            "Store #43: 14.451\n",
            "Store #44: 21.282\n",
            "Store #45: 21.492\n",
            "Store #46: 18.415\n",
            "Store #47: 26.67\n",
            "Store #48: 17.231\n",
            "Store #49: 12.426\n",
            "Store #50: 12.176\n",
            "Store #51: 13.813\n",
            "Store #52: 10.598\n",
            "Store #53: 6.711\n",
            "Store #54: 55.836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2BmcghU6GMo"
      },
      "source": [
        "Мы видим, что RMSE снизилась по сравнению с бэйзлайном, однако точность прогнозирования сильно зависит от магазина.\n",
        "\n",
        "Используем данную модель для совершения финальных прогнозов, добавив при этом валидационные данные."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TqlUvu_61NQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkrJiOoLHx2L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfLtWyibGKo7"
      },
      "source": [
        "date = (np.array('2017-08-01', dtype=np.datetime64) + np.arange(15)).astype(str)\n",
        "df_test_transformed = None\n",
        "for store in df_submission.STORE_ID.unique():\n",
        "  if df_test_transformed is None:\n",
        "    df_test_transformed = list( product(date,[store],articles[store] ))\n",
        "  else:\n",
        "    df_test_transformed.extend( list( product(date,[store],articles[store] )) )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i8RjeGhIJ0r"
      },
      "source": [
        "df_test_transformed = pd.DataFrame(df_test_transformed,columns = ['DAY_ID','STORE_ID','ARTICLE_ID'])\n",
        "df_test_transformed = pd.merge(df_test_transformed,df_test,how='outer')\n",
        "df_test_transformed = pd.merge(df_test_transformed,df_sales_count)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PzSGq0lIKFk"
      },
      "source": [
        "df_test_transformed['IS_HOLIDAY'] = df_test_transformed['DAY_ID'].apply(lambda x: x in df_holidays['DAY_ID'].values)\n",
        "df_test_transformed['WEEKDAY'] = df_test_transformed['DAY_ID'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d').weekday())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJxEvYHyJiWk"
      },
      "source": [
        "df_test_transformed.fillna(0,inplace=True)\n",
        "df_test_transformed.sort_values(by = ['DAY_ID','STORE_ID','ARTICLE_ID'],inplace=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjGJQnSUJA3D"
      },
      "source": [
        "df_test_transformed['SALES'] = 0."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuiIgQxT5ku0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd7e3cb9-f13b-4adf-ce4d-0d42276f123f"
      },
      "source": [
        "\n",
        "for store in res.STORE_ID.unique():\n",
        "  ds = res[res.STORE_ID==store]\n",
        "  ds.sort_values(by=['DAY_ID','ARTICLE_ID'],inplace=True)\n",
        "\n",
        "  ids = ds.ARTICLE_ID.unique()\n",
        "  ids.sort()\n",
        "  N_items = ids.shape[0]\n",
        "  id_int = {ids[i]:i for i in range(N_items)}\n",
        "  int_id = {i:ids[i] for i in range(N_items)}\n",
        "\n",
        "  ds['ind'] = ds['ARTICLE_ID'].apply(lambda x: id_int[x])\n",
        "  ds['WEEKDAY'] = ds['WEEKDAY']*N_items+ds['ind']\n",
        "  ds['IS_ACTION'] = ds['IS_ACTION']*ds['ind']\n",
        "  ds['IS_HOLIDAY'] = ds['IS_HOLIDAY']*ds['ind']\n",
        "\n",
        "\n",
        "  TS = ds.SALES.values.reshape(-1,N_items)\n",
        "\n",
        "  A = ds.IS_ACTION.values.reshape(-1,N_items)\n",
        "  We = ds.WEEKDAY.values.reshape(-1,N_items)\n",
        "  Sa = ds.SALES_COUNT.values.reshape(-1,N_items)\n",
        "  H = ds.IS_HOLIDAY.values.reshape(-1,N_items)\n",
        "  \n",
        "  X,y,A,We,S,H = inout_seq(TS,A,We,Sa,H,train_len,pred_len)\n",
        "\n",
        "  X,y,A,We,S,H = from_numpy(X).to(device).float(),from_numpy(y).to(device).float(),from_numpy(A).to(device).long(),from_numpy(We).to(device).long(), \\\n",
        "  from_numpy(S).to(device).float(),from_numpy(H).to(device).long()\n",
        "\n",
        "  model = LSTM(input_size=N_items+1, hidden_size=hidden_size, output_size=N_items, pred_len=pred_len,num_layers=num_layers,dropout=dropout).to(device)\n",
        "  opt = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "  N = X.shape[0]\n",
        "  crit = nn.MSELoss()\n",
        "  print(\"Store #{}\".format(store))\n",
        "\n",
        "  for epoch in range(n_epoches):\n",
        "    model.train()\n",
        "    inds = torch.randperm(N).to(device)\n",
        "    for i in range(N//bs):\n",
        "      opt.zero_grad()\n",
        "      X_batch,y_batch,A_batch,We_batch,S_batch,H_batch = X[inds[i*bs:(i+1)*bs]],y[inds[i*bs:(i+1)*bs]],A[inds[i*bs:(i+1)*bs]],We[inds[i*bs:(i+1)*bs]], \\\n",
        "      S[inds[i*bs:(i+1)*bs]], H[inds[i*bs:(i+1)*bs]]\n",
        "\n",
        "      preds = model(X_batch,A_batch,We_batch,S_batch,H_batch)\n",
        "      loss = crit(preds*(y_batch!=0),y_batch)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  ds_test = df_test_transformed[df_test_transformed.STORE_ID==store]\n",
        "  ds_test.sort_values(by=['DAY_ID','ARTICLE_ID'],inplace=True)\n",
        "\n",
        "  X_test = torch.unsqueeze(from_numpy(np.concatenate([ TS[-train_len:],Sa[-train_len:,[0]] ],axis=1)).to(device).float(),0)\n",
        "  A_test = torch.unsqueeze(from_numpy(ds_test.IS_ACTION.values.reshape(-1,N_items)).to(device).long(),0)\n",
        "  We_test = torch.unsqueeze(from_numpy(ds_test.WEEKDAY.values.reshape(-1,N_items)).to(device).long(),0)\n",
        "  S_test = torch.unsqueeze(from_numpy(ds_test.SALES_COUNT.values.reshape(-1,N_items)).to(device).float(),0)\n",
        "  H_test = torch.unsqueeze(from_numpy(ds_test.IS_ACTION.values.reshape(-1,N_items)).to(device).long(),0)\n",
        "\n",
        "  preds = model(X_test,A_test,We_test,S_test,H_test)[0].cpu().detach().numpy().reshape(-1)\n",
        "  df_test_transformed.loc[df_test_transformed.STORE_ID==store,'SALES'] = preds\n",
        "  "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Store #1\n",
            "Store #2\n",
            "Store #3\n",
            "Store #4\n",
            "Store #5\n",
            "Store #6\n",
            "Store #7\n",
            "Store #8\n",
            "Store #9\n",
            "Store #10\n",
            "Store #11\n",
            "Store #12\n",
            "Store #13\n",
            "Store #14\n",
            "Store #15\n",
            "Store #16\n",
            "Store #17\n",
            "Store #18\n",
            "Store #19\n",
            "Store #20\n",
            "Store #21\n",
            "Store #22\n",
            "Store #23\n",
            "Store #24\n",
            "Store #25\n",
            "Store #26\n",
            "Store #27\n",
            "Store #28\n",
            "Store #29\n",
            "Store #30\n",
            "Store #31\n",
            "Store #32\n",
            "Store #33\n",
            "Store #34\n",
            "Store #35\n",
            "Store #36\n",
            "Store #37\n",
            "Store #38\n",
            "Store #39\n",
            "Store #40\n",
            "Store #41\n",
            "Store #42\n",
            "Store #43\n",
            "Store #44\n",
            "Store #45\n",
            "Store #46\n",
            "Store #47\n",
            "Store #48\n",
            "Store #49\n",
            "Store #50\n",
            "Store #51\n",
            "Store #52\n",
            "Store #53\n",
            "Store #54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW134XR1QRxu"
      },
      "source": [
        "final = pd.merge(df_test_transformed[['DAY_ID','STORE_ID','ARTICLE_ID','SALES']],df_test[['DAY_ID','STORE_ID','ARTICLE_ID']],how='inner')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84P84BPJhi12"
      },
      "source": [
        "final.to_csv('/content/drive/MyDrive/regression/final_reg.csv')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY-mMGpUVhU_"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8LNNcbGqfOc"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwSMg3lXPfS8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g69tBmeL8t69"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}